{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50af4eff",
   "metadata": {},
   "source": [
    "## Step 1: Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42747b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1048575, 76)\n",
      "\n",
      "Columns: ['(tic) Ticker Symbol', '(datadate) Data Date - Dividends', '(conm) Company Name', '(cusip) CUSIP', '(cik) CIK Number', '(exchg) Stock Exchange Code', '(secstat) Security Status Marker', '(fic) Current ISO Country Code - Incorporation', '(tpci) Issue Type Code', '(add1) Address Line 1', '(add2) Address Line 2', '(add3) Address Line 3', '(add4) Address Line 4', '(addzip) Postal Code', '(busdesc) S&P Business Description', '(city) City', '(conml) Company Legal Name', '(costat) Active/Inactive Status Marker', '(county) County Code', '(dldte) Research Company Deletion Date', '(dlrsn) Research Co Reason for Deletion', '(ein) Employer Identification Number', '(fax) Fax Number', '(fyrc) Current Fiscal Year End Month', '(ggroup) GIC Groups', '(gind) GIC Industries', '(gsector) GIC Sectors', '(gsubind) GIC Sub-Industries', '(idbflag) International, Domestic, Both Indicator', '(incorp) Current State/Province of Incorporation Code', '(ipodate) Company Initial Public Offering Date', '(loc) Current ISO Country Code - Headquarters', '(naics) North American Industry Classification Code', '(phone) Phone Number', '(prican) Current Primary Issue Tag - Canada', '(prirow) Primary Issue Tag - Rest of World', '(priusa) Current Primary Issue Tag - US', '(sic) Standard Industry Classification Code', '(spcindcd) S&P Industry Sector Code', '(spcseccd) S&P Economic Sector Code', '(spcsrc) S&P Quality Ranking - Current', '(state) State/Province', '(stko) Stock Ownership Code', '(weburl) Web URL', '(adrrc) ADR Ratio - Daily', '(ajexdi) Adjustment Factor (Issue)-Cumulative by Ex-Date', '(anncdate) Dividend Declaration Date', '(capgn) Capital Gains - Daily', '(capgnpaydate) Capital Gains Payment Date', '(cheqv) Cash Equivalent Distributions', '(cheqvpaydate) Cash Equivalent Distributions per Share Payment ', '(cshoc) Shares Outstanding', '(cshtrd) Trading Volume - Daily', '(curcdd) ISO Currency Code - Daily', '(curcddv) ISO Currency Code - Dividend', '(div) Dividends per Share - Ex Date - Daily (Issue)', '(divd) Cash Dividends - Daily', '(divdpaydate) Cash Dividends - Daily Payment Date', '(divdpaydateind) Cash Dividends - Daily Payment Date Indicator', '(divsp) Special Cash Dividends - Daily', '(divsppaydate) Special Cash Dividends - Daily Payment Date', '(dvi) Indicated Annual Dividend - Current', '(dvrated) Indicated Annual Dividend Rate - Daily', '(eps) Current EPS', '(epsmo) Current EPS Month', '(iid) Issue ID - Dividends', '(paydate) Dividend Payment Date', '(paydateind) Dividend Payment Date Indicator', '(prccd) Price - Close - Daily', '(prchd) Price - High - Daily', '(prcld) Price - Low - Daily', '(prcod) Price - Open - Daily', '(prcstd) Price Status Code - Daily', '(recorddate) Dividend Record Date', '(trfd) Daily Total Return Factor', '(gvkey) Global Company Key - Dividends']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(tic) Ticker Symbol</th>\n",
       "      <th>(datadate) Data Date - Dividends</th>\n",
       "      <th>(conm) Company Name</th>\n",
       "      <th>(cusip) CUSIP</th>\n",
       "      <th>(cik) CIK Number</th>\n",
       "      <th>(exchg) Stock Exchange Code</th>\n",
       "      <th>(secstat) Security Status Marker</th>\n",
       "      <th>(fic) Current ISO Country Code - Incorporation</th>\n",
       "      <th>(tpci) Issue Type Code</th>\n",
       "      <th>(add1) Address Line 1</th>\n",
       "      <th>...</th>\n",
       "      <th>(paydate) Dividend Payment Date</th>\n",
       "      <th>(paydateind) Dividend Payment Date Indicator</th>\n",
       "      <th>(prccd) Price - Close - Daily</th>\n",
       "      <th>(prchd) Price - High - Daily</th>\n",
       "      <th>(prcld) Price - Low - Daily</th>\n",
       "      <th>(prcod) Price - Open - Daily</th>\n",
       "      <th>(prcstd) Price Status Code - Daily</th>\n",
       "      <th>(recorddate) Dividend Record Date</th>\n",
       "      <th>(trfd) Daily Total Return Factor</th>\n",
       "      <th>(gvkey) Global Company Key - Dividends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-09</td>\n",
       "      <td>AMERICAN AIRLINES GROUP INC</td>\n",
       "      <td>02376R102</td>\n",
       "      <td>6201</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>1 Skyview Drive</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.60</td>\n",
       "      <td>25.44</td>\n",
       "      <td>23.4501</td>\n",
       "      <td>23.95</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-10</td>\n",
       "      <td>AMERICAN AIRLINES GROUP INC</td>\n",
       "      <td>02376R102</td>\n",
       "      <td>6201</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>1 Skyview Drive</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.88</td>\n",
       "      <td>25.17</td>\n",
       "      <td>24.4100</td>\n",
       "      <td>24.54</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-11</td>\n",
       "      <td>AMERICAN AIRLINES GROUP INC</td>\n",
       "      <td>02376R102</td>\n",
       "      <td>6201</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>1 Skyview Drive</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.99</td>\n",
       "      <td>27.20</td>\n",
       "      <td>25.3700</td>\n",
       "      <td>25.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-12</td>\n",
       "      <td>AMERICAN AIRLINES GROUP INC</td>\n",
       "      <td>02376R102</td>\n",
       "      <td>6201</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>1 Skyview Drive</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.45</td>\n",
       "      <td>26.71</td>\n",
       "      <td>25.4500</td>\n",
       "      <td>26.20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-13</td>\n",
       "      <td>AMERICAN AIRLINES GROUP INC</td>\n",
       "      <td>02376R102</td>\n",
       "      <td>6201</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>1 Skyview Drive</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.23</td>\n",
       "      <td>26.30</td>\n",
       "      <td>25.5201</td>\n",
       "      <td>25.61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  (tic) Ticker Symbol (datadate) Data Date - Dividends  \\\n",
       "0                 AAL                       2013-12-09   \n",
       "1                 AAL                       2013-12-10   \n",
       "2                 AAL                       2013-12-11   \n",
       "3                 AAL                       2013-12-12   \n",
       "4                 AAL                       2013-12-13   \n",
       "\n",
       "           (conm) Company Name (cusip) CUSIP  (cik) CIK Number  \\\n",
       "0  AMERICAN AIRLINES GROUP INC     02376R102              6201   \n",
       "1  AMERICAN AIRLINES GROUP INC     02376R102              6201   \n",
       "2  AMERICAN AIRLINES GROUP INC     02376R102              6201   \n",
       "3  AMERICAN AIRLINES GROUP INC     02376R102              6201   \n",
       "4  AMERICAN AIRLINES GROUP INC     02376R102              6201   \n",
       "\n",
       "   (exchg) Stock Exchange Code (secstat) Security Status Marker  \\\n",
       "0                           14                                A   \n",
       "1                           14                                A   \n",
       "2                           14                                A   \n",
       "3                           14                                A   \n",
       "4                           14                                A   \n",
       "\n",
       "  (fic) Current ISO Country Code - Incorporation  (tpci) Issue Type Code  \\\n",
       "0                                            USA                       0   \n",
       "1                                            USA                       0   \n",
       "2                                            USA                       0   \n",
       "3                                            USA                       0   \n",
       "4                                            USA                       0   \n",
       "\n",
       "  (add1) Address Line 1  ...  (paydate) Dividend Payment Date  \\\n",
       "0       1 Skyview Drive  ...                              NaT   \n",
       "1       1 Skyview Drive  ...                              NaT   \n",
       "2       1 Skyview Drive  ...                              NaT   \n",
       "3       1 Skyview Drive  ...                              NaT   \n",
       "4       1 Skyview Drive  ...                              NaT   \n",
       "\n",
       "   (paydateind) Dividend Payment Date Indicator  \\\n",
       "0                                           NaN   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3                                           NaN   \n",
       "4                                           NaN   \n",
       "\n",
       "   (prccd) Price - Close - Daily (prchd) Price - High - Daily  \\\n",
       "0                          24.60                        25.44   \n",
       "1                          24.88                        25.17   \n",
       "2                          25.99                        27.20   \n",
       "3                          25.45                        26.71   \n",
       "4                          26.23                        26.30   \n",
       "\n",
       "  (prcld) Price - Low - Daily (prcod) Price - Open - Daily  \\\n",
       "0                     23.4501                        23.95   \n",
       "1                     24.4100                        24.54   \n",
       "2                     25.3700                        25.44   \n",
       "3                     25.4500                        26.20   \n",
       "4                     25.5201                        25.61   \n",
       "\n",
       "  (prcstd) Price Status Code - Daily (recorddate) Dividend Record Date  \\\n",
       "0                                3.0                               NaT   \n",
       "1                                3.0                               NaT   \n",
       "2                                3.0                               NaT   \n",
       "3                                3.0                               NaT   \n",
       "4                                3.0                               NaT   \n",
       "\n",
       "   (trfd) Daily Total Return Factor (gvkey) Global Company Key - Dividends  \n",
       "0                               1.0                                   1045  \n",
       "1                               1.0                                   1045  \n",
       "2                               1.0                                   1045  \n",
       "3                               1.0                                   1045  \n",
       "4                               1.0                                   1045  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "\n",
    "# Load the Wharton data\n",
    "file_path = 'WhartonDataSource.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab5951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column mapping (shortened name -> full name):\n",
      "tic -> Ticker Symbol\n",
      "datadate -> Data Date - Dividends\n",
      "conm -> Company Name\n",
      "cusip -> CUSIP\n",
      "cik -> CIK Number\n",
      "exchg -> Stock Exchange Code\n",
      "secstat -> Security Status Marker\n",
      "fic -> Current ISO Country Code - Incorporation\n",
      "tpci -> Issue Type Code\n",
      "add1 -> Address Line 1\n",
      "add2 -> Address Line 2\n",
      "add3 -> Address Line 3\n",
      "add4 -> Address Line 4\n",
      "addzip -> Postal Code\n",
      "busdesc -> S&P Business Description\n",
      "city -> City\n",
      "conml -> Company Legal Name\n",
      "costat -> Active/Inactive Status Marker\n",
      "county -> County Code\n",
      "dldte -> Research Company Deletion Date\n",
      "dlrsn -> Research Co Reason for Deletion\n",
      "ein -> Employer Identification Number\n",
      "fax -> Fax Number\n",
      "fyrc -> Current Fiscal Year End Month\n",
      "ggroup -> GIC Groups\n",
      "gind -> GIC Industries\n",
      "gsector -> GIC Sectors\n",
      "gsubind -> GIC Sub-Industries\n",
      "idbflag -> International, Domestic, Both Indicator\n",
      "incorp -> Current State/Province of Incorporation Code\n",
      "ipodate -> Company Initial Public Offering Date\n",
      "loc -> Current ISO Country Code - Headquarters\n",
      "naics -> North American Industry Classification Code\n",
      "phone -> Phone Number\n",
      "prican -> Current Primary Issue Tag - Canada\n",
      "prirow -> Primary Issue Tag - Rest of World\n",
      "priusa -> Current Primary Issue Tag - US\n",
      "sic -> Standard Industry Classification Code\n",
      "spcindcd -> S&P Industry Sector Code\n",
      "spcseccd -> S&P Economic Sector Code\n",
      "spcsrc -> S&P Quality Ranking - Current\n",
      "state -> State/Province\n",
      "stko -> Stock Ownership Code\n",
      "weburl -> Web URL\n",
      "adrrc -> ADR Ratio - Daily\n",
      "ajexdi -> Adjustment Factor (Issue\n",
      "anncdate -> Dividend Declaration Date\n",
      "capgn -> Capital Gains - Daily\n",
      "capgnpaydate -> Capital Gains Payment Date\n",
      "cheqv -> Cash Equivalent Distributions\n",
      "cheqvpaydate -> Cash Equivalent Distributions per Share Payment\n",
      "cshoc -> Shares Outstanding\n",
      "cshtrd -> Trading Volume - Daily\n",
      "curcdd -> ISO Currency Code - Daily\n",
      "curcddv -> ISO Currency Code - Dividend\n",
      "div -> Dividends per Share - Ex Date - Daily (Issue\n",
      "divd -> Cash Dividends - Daily\n",
      "divdpaydate -> Cash Dividends - Daily Payment Date\n",
      "divdpaydateind -> Cash Dividends - Daily Payment Date Indicator\n",
      "divsp -> Special Cash Dividends - Daily\n",
      "divsppaydate -> Special Cash Dividends - Daily Payment Date\n",
      "dvi -> Indicated Annual Dividend - Current\n",
      "dvrated -> Indicated Annual Dividend Rate - Daily\n",
      "eps -> Current EPS\n",
      "epsmo -> Current EPS Month\n",
      "iid -> Issue ID - Dividends\n",
      "paydate -> Dividend Payment Date\n",
      "paydateind -> Dividend Payment Date Indicator\n",
      "prccd -> Price - Close - Daily\n",
      "prchd -> Price - High - Daily\n",
      "prcld -> Price - Low - Daily\n",
      "prcod -> Price - Open - Daily\n",
      "prcstd -> Price Status Code - Daily\n",
      "recorddate -> Dividend Record Date\n",
      "trfd -> Daily Total Return Factor\n",
      "gvkey -> Global Company Key - Dividends\n"
     ]
    }
   ],
   "source": [
    "def extract_and_rename_columns(df):\n",
    "    \"\"\"\n",
    "    Extract shortened column names from parentheses in full column names.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with column names in format: (SHORT_NAME) Full Name Description\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (modified_df, column_mapping)\n",
    "        - modified_df: DataFrame with columns renamed to shortened names\n",
    "        - column_mapping: Dict mapping short names to full descriptions\n",
    "    \"\"\"\n",
    "    column_mapping = {}\n",
    "    rename_dict = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col.startswith('(') and ')' in col:\n",
    "            short_name = col.split(')')[0][1:]  # Extract text inside parentheses\n",
    "            full_name = col.split(')')[1].strip()  # Extract text after parentheses\n",
    "            column_mapping[short_name] = full_name\n",
    "            rename_dict[col] = short_name\n",
    "    \n",
    "    # Print the mapping for reference\n",
    "    print(\"Column mapping (shortened name -> full name):\")\n",
    "    for short, full in column_mapping.items():\n",
    "        print(f\"  {short:15} -> {full}\")\n",
    "    \n",
    "    # Rename columns in the dataframe\n",
    "    df_renamed = df.rename(columns=rename_dict)\n",
    "    \n",
    "    return df_renamed, column_mapping\n",
    "\n",
    "# Call the function\n",
    "df, col_mapping = extract_and_rename_columns(df)\n",
    "print(f\"\\nRenamed {len(col_mapping)} columns successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb543e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49e6a1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key column info:\n",
      "Available key columns: ['tic', 'datadate', 'prccd', 'ajexdi', 'cshtrd', 'trfd']\n",
      "\n",
      "Data types:\n",
      "tic                 object\n",
      "datadate    datetime64[ns]\n",
      "prccd              float64\n",
      "ajexdi             float64\n",
      "cshtrd             float64\n",
      "trfd               float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "tic             0\n",
      "datadate        0\n",
      "prccd          17\n",
      "ajexdi         17\n",
      "cshtrd         25\n",
      "trfd        26100\n",
      "dtype: int64\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>datadate</th>\n",
       "      <th>prccd</th>\n",
       "      <th>ajexdi</th>\n",
       "      <th>cshtrd</th>\n",
       "      <th>trfd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-09</td>\n",
       "      <td>24.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43167060.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-10</td>\n",
       "      <td>24.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18648140.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-11</td>\n",
       "      <td>25.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38584270.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-12</td>\n",
       "      <td>25.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19977100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-13</td>\n",
       "      <td>26.23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12189890.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-16</td>\n",
       "      <td>26.61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13181320.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-17</td>\n",
       "      <td>26.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11398040.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-18</td>\n",
       "      <td>26.23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9989747.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-19</td>\n",
       "      <td>26.12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6908812.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-20</td>\n",
       "      <td>26.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7527964.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tic   datadate  prccd  ajexdi      cshtrd  trfd\n",
       "0  AAL 2013-12-09  24.60     1.0  43167060.0   1.0\n",
       "1  AAL 2013-12-10  24.88     1.0  18648140.0   1.0\n",
       "2  AAL 2013-12-11  25.99     1.0  38584270.0   1.0\n",
       "3  AAL 2013-12-12  25.45     1.0  19977100.0   1.0\n",
       "4  AAL 2013-12-13  26.23     1.0  12189890.0   1.0\n",
       "5  AAL 2013-12-16  26.61     1.0  13181320.0   1.0\n",
       "6  AAL 2013-12-17  26.10     1.0  11398040.0   1.0\n",
       "7  AAL 2013-12-18  26.23     1.0   9989747.0   1.0\n",
       "8  AAL 2013-12-19  26.12     1.0   6908812.0   1.0\n",
       "9  AAL 2013-12-20  26.33     1.0   7527964.0   1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect key columns\n",
    "print(\"Key column info:\")\n",
    "key_cols = ['tic', 'datadate', 'prccd', 'ajexdi', 'cshtrd', 'trfd']\n",
    "available_cols = [col for col in key_cols if col in df.columns]\n",
    "\n",
    "print(f\"Available key columns: {available_cols}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df[available_cols].dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df[available_cols].isnull().sum())\n",
    "print(f\"\\nSample data:\")\n",
    "df[available_cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e52899fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: 2000-01-03 00:00:00 to 2025-12-10 00:00:00\n",
      "Number of unique tickers: 167\n",
      "\n",
      "Top 10 tickers by number of records:\n",
      "tic\n",
      "LNT     6526\n",
      "MO      6526\n",
      "PSA     6526\n",
      "HBAN    6526\n",
      "TXN     6526\n",
      "ADP     6526\n",
      "TXT     6526\n",
      "JCI     6526\n",
      "MS      6526\n",
      "RF      6526\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check date range and unique tickers\n",
    "df['(datadate) Data Date - Dividends'] = pd.to_datetime(df['datadate'])\n",
    "\n",
    "print(f\"Date range: {df['datadate'].min()} to {df['datadate'].max()}\")\n",
    "print(f\"Number of unique tickers: {df['tic'].nunique()}\")\n",
    "print(f\"\\nTop 10 tickers by number of records:\")\n",
    "print(df['tic'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d42b33",
   "metadata": {},
   "source": [
    "## Step 2: Create WhartonDataSource Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ec8da11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WhartonDataSource class created successfully!\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class DataSource(ABC):\n",
    "    \"\"\"Interface for fetching historical market data.\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_historical_data(self, tickers: List[str], start_date: str, end_date: str) -> pd.DataFrame:\n",
    "        \"\"\"Fetch historical data for given tickers and date range.\"\"\"\n",
    "        pass\n",
    "\n",
    "class WhartonDataSource(DataSource):\n",
    "    \"\"\"\n",
    "    Implementation of DataSource using Wharton WRDS data from Excel file.\n",
    "    \n",
    "    Expected columns:\n",
    "    - tic: Ticker Symbol\n",
    "    - datadate: Data Date\n",
    "    - prccd: Price Close Daily\n",
    "    - ajexdi: Adjustment Factor (cumulative by ex-date)\n",
    "    - cshtrd: Trading Volume Daily\n",
    "    - trfd: Daily Total Return Factor (optional, alternative to prccd*ajexdi)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_path: str, use_trfd: bool = False):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path : str\n",
    "            Path to the Wharton Excel/CSV file\n",
    "        use_trfd : bool\n",
    "            If True, use trfd (total return factor) directly.\n",
    "            If False, calculate adjusted price as prccd * ajexdi\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "        self.use_trfd = use_trfd\n",
    "        self.data = None\n",
    "        self._load_data()\n",
    "    \n",
    "    def _load_data(self):\n",
    "        \"\"\"Load and prepare data from file.\"\"\"\n",
    "        if not os.path.exists(self.file_path):\n",
    "            raise FileNotFoundError(f\"Data file not found at {self.file_path}\")\n",
    "        \n",
    "        # Load file (supports .xlsx and .csv)\n",
    "        if self.file_path.endswith('.xlsx') or self.file_path.endswith('.xls'):\n",
    "            self.data = pd.read_excel(self.file_path)\n",
    "        else:\n",
    "            self.data = pd.read_csv(self.file_path)\n",
    "        \n",
    "        # Ensure required columns exist\n",
    "        required_cols = ['tic', 'datadate']\n",
    "        missing_cols = [col for col in required_cols if col not in self.data.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "        \n",
    "        # Convert date column\n",
    "        self.data['datadate'] = pd.to_datetime(self.data['datadate'])\n",
    "        \n",
    "        # Calculate adjusted close price\n",
    "        if self.use_trfd:\n",
    "            if 'trfd' not in self.data.columns:\n",
    "                raise ValueError(\"trfd column not found but use_trfd=True\")\n",
    "            self.data['Adj Close'] = self.data['trfd']\n",
    "        else:\n",
    "            if 'prccd' not in self.data.columns or 'ajexdi' not in self.data.columns:\n",
    "                raise ValueError(\"prccd and ajexdi columns required when use_trfd=False\")\n",
    "            self.data['Adj Close'] = self.data['prccd'] * self.data['ajexdi']\n",
    "        \n",
    "        # Add volume if available\n",
    "        if 'cshtrd' in self.data.columns:\n",
    "            self.data['Volume'] = self.data['cshtrd']\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} records for {self.data['tic'].nunique()} tickers\")\n",
    "        print(f\"Date range: {self.data['datadate'].min()} to {self.data['datadate'].max()}\")\n",
    "    \n",
    "    def get_historical_data(self, tickers: List[str], start_date: str, end_date: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fetch historical adjusted prices for given tickers and date range.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Index: dates, Columns: tickers, Values: adjusted close prices\n",
    "        \"\"\"\n",
    "        start_ts = pd.Timestamp(start_date)\n",
    "        end_ts = pd.Timestamp(end_date)\n",
    "        \n",
    "        # Filter by date range and tickers\n",
    "        mask = (\n",
    "            (self.data['datadate'] >= start_ts) & \n",
    "            (self.data['datadate'] <= end_ts) & \n",
    "            (self.data['tic'].isin(tickers))\n",
    "        )\n",
    "        filtered = self.data.loc[mask, ['tic', 'datadate', 'Adj Close']].copy()\n",
    "        \n",
    "        if filtered.empty:\n",
    "            print(f\"Warning: No data found for specified tickers and date range\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Pivot to get tickers as columns, dates as index\n",
    "        result = filtered.pivot(index='datadate', columns='tic', values='Adj Close')\n",
    "        result = result.sort_index()\n",
    "        \n",
    "        # Report missing tickers\n",
    "        missing_tickers = set(tickers) - set(result.columns)\n",
    "        if missing_tickers:\n",
    "            print(f\"Warning: No data found for tickers: {missing_tickers}\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_historical_data_with_volume(self, tickers: List[str], start_date: str, end_date: str) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Fetch historical price and volume data, organized by ticker.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, pd.DataFrame]\n",
    "            For each ticker: DataFrame indexed by date with 'Adj Close' and 'Volume' columns\n",
    "        \"\"\"\n",
    "        start_ts = pd.Timestamp(start_date)\n",
    "        end_ts = pd.Timestamp(end_date)\n",
    "        \n",
    "        result = {}\n",
    "        \n",
    "        for ticker in tickers:\n",
    "            mask = (\n",
    "                (self.data['datadate'] >= start_ts) & \n",
    "                (self.data['datadate'] <= end_ts) & \n",
    "                (self.data['tic'] == ticker)\n",
    "            )\n",
    "            ticker_data = self.data.loc[mask, ['datadate', 'Adj Close', 'Volume']].copy()\n",
    "            \n",
    "            if ticker_data.empty:\n",
    "                print(f\"Warning: No data found for {ticker}\")\n",
    "                continue\n",
    "            \n",
    "            ticker_data = ticker_data.set_index('datadate').sort_index()\n",
    "            result[ticker] = ticker_data\n",
    "        \n",
    "        return result\n",
    "\n",
    "print(\"WhartonDataSource class created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae710f",
   "metadata": {},
   "source": [
    "## Step 3: Test Basic Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c984968",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing required columns: ['tic', 'datadate']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Initialize the data source\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m wharton_source = \u001b[43mWhartonDataSource\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mWhartonDataSource.xlsx\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_trfd\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Test with a few tickers\u001b[39;00m\n\u001b[32m      5\u001b[39m test_tickers = [\u001b[33m'\u001b[39m\u001b[33mAAPL\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMSFT\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mGOOGL\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mSPY\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mWhartonDataSource.__init__\u001b[39m\u001b[34m(self, file_path, use_trfd)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28mself\u001b[39m.use_trfd = use_trfd\n\u001b[32m     36\u001b[39m \u001b[38;5;28mself\u001b[39m.data = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mWhartonDataSource._load_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     52\u001b[39m missing_cols = [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m required_cols \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data.columns]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing_cols:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Convert date column\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mself\u001b[39m.data[\u001b[33m'\u001b[39m\u001b[33mdatadate\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(\u001b[38;5;28mself\u001b[39m.data[\u001b[33m'\u001b[39m\u001b[33mdatadate\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mValueError\u001b[39m: Missing required columns: ['tic', 'datadate']"
     ]
    }
   ],
   "source": [
    "# Initialize the data source\n",
    "wharton_source = WhartonDataSource('WhartonDataSource.xlsx', use_trfd=False)\n",
    "\n",
    "# Test with a few tickers\n",
    "test_tickers = ['AAPL', 'MSFT', 'GOOGL', 'SPY']\n",
    "start_date = '2024-01-01'\n",
    "end_date = '2024-12-31'\n",
    "\n",
    "price_data = wharton_source.get_historical_data(test_tickers, start_date, end_date)\n",
    "print(f\"\\nRetrieved data shape: {price_data.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "price_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67ac57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing data\n",
    "print(\"Missing data per ticker:\")\n",
    "print(price_data.isnull().sum())\n",
    "print(f\"\\nData completeness: {(1 - price_data.isnull().sum() / len(price_data)) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3ebd7a",
   "metadata": {},
   "source": [
    "## Step 4: Test with SPY Verification (If Holdings File Available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9afc63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary functions from data_source module\n",
    "import sys\n",
    "sys.path.append('/Users/bouse/developer/CDS/DataQuality25/millennium-data-quality-25-26/backtester')\n",
    "from data_source import YahooFinanceDataSource\n",
    "\n",
    "# Check if holdings file exists\n",
    "holdings_file = 'holdings-daily-us-en-spy.xlsx'\n",
    "if os.path.exists(holdings_file):\n",
    "    print(\"Holdings file found! Running SPY verification...\")\n",
    "    \n",
    "    # Use YahooFinanceDataSource methods for holdings and portfolio calculation\n",
    "    yahoo_source = YahooFinanceDataSource()\n",
    "    holdings_df = yahoo_source.read_spy_holdings(holdings_file)\n",
    "    \n",
    "    # Fix ticker format\n",
    "    holdings_df['Ticker'] = holdings_df['Ticker'].replace({\n",
    "        'BRK.B': 'BRK-B',\n",
    "        'BF.B': 'BF-B',\n",
    "        '-': 'USD'\n",
    "    })\n",
    "    \n",
    "    print(f\"Found {len(holdings_df)} constituents\")\n",
    "    \n",
    "    # Get data for SPY and constituents\n",
    "    tickers = ['SPY'] + holdings_df['Ticker'].tolist()\n",
    "    price_data = wharton_source.get_historical_data(tickers, start_date, end_date)\n",
    "    \n",
    "    if 'SPY' in price_data.columns:\n",
    "        spy_data = price_data['SPY'].copy()\n",
    "        weighted_portfolio = yahoo_source.calculate_weighted_portfolio(holdings_df, price_data)\n",
    "        \n",
    "        print(f\"\\nSPY data points: {len(spy_data)}\")\n",
    "        print(f\"Portfolio data points: {len(weighted_portfolio)}\")\n",
    "    else:\n",
    "        print(\"SPY data not available in Wharton source\")\n",
    "else:\n",
    "    print(f\"Holdings file not found: {holdings_file}\")\n",
    "    print(\"Skipping SPY verification test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8013b7c3",
   "metadata": {},
   "source": [
    "## Step 5: Compare Wharton vs Yahoo Finance (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77102fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare a single ticker from both sources\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_ticker = 'AAPL'\n",
    "compare_start = '2024-01-01'\n",
    "compare_end = '2024-03-31'\n",
    "\n",
    "# Get Wharton data\n",
    "wharton_prices = wharton_source.get_historical_data([test_ticker], compare_start, compare_end)\n",
    "\n",
    "# Get Yahoo data for comparison (if available)\n",
    "try:\n",
    "    import yfinance as yf\n",
    "    yahoo_data = yf.download(test_ticker, start=compare_start, end=compare_end, auto_adjust=False)\n",
    "    yahoo_prices = yahoo_data['Adj Close']\n",
    "    \n",
    "    # Plot comparison\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "    \n",
    "    # Price comparison\n",
    "    ax1.plot(wharton_prices.index, wharton_prices[test_ticker], label='Wharton', alpha=0.7)\n",
    "    ax1.plot(yahoo_prices.index, yahoo_prices, label='Yahoo Finance', alpha=0.7)\n",
    "    ax1.set_title(f'{test_ticker} Price Comparison')\n",
    "    ax1.set_ylabel('Adjusted Close Price')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Difference\n",
    "    aligned = pd.concat([wharton_prices[test_ticker], yahoo_prices], axis=1, join='inner')\n",
    "    aligned.columns = ['Wharton', 'Yahoo']\n",
    "    aligned['Diff'] = aligned['Wharton'] - aligned['Yahoo']\n",
    "    aligned['Diff_Pct'] = (aligned['Diff'] / aligned['Yahoo']) * 100\n",
    "    \n",
    "    ax2.plot(aligned.index, aligned['Diff_Pct'])\n",
    "    ax2.set_title('Percentage Difference (Wharton - Yahoo)')\n",
    "    ax2.set_ylabel('Difference %')\n",
    "    ax2.set_xlabel('Date')\n",
    "    ax2.grid(True)\n",
    "    ax2.axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nDifference Statistics:\")\n",
    "    print(f\"Mean difference: {aligned['Diff_Pct'].mean():.4f}%\")\n",
    "    print(f\"Max difference: {aligned['Diff_Pct'].max():.4f}%\")\n",
    "    print(f\"Correlation: {aligned['Wharton'].corr(aligned['Yahoo']):.6f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not compare with Yahoo Finance: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd85dc38",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Add `WhartonDataSource` to [data_source.py](data_source.py)\n",
    "2. Implement additional methods:\n",
    "   - `read_spy_holdings()` (reuse from YahooFinanceDataSource)\n",
    "   - `calculate_weighted_portfolio()` (reuse)\n",
    "   - `detect_price_anomalies()` (reuse)\n",
    "   - `verify_spy_vs_constituents()` (reuse)\n",
    "3. Run full backtester tests with Wharton data\n",
    "4. Compare results with Yahoo Finance data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
