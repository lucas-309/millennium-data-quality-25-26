{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05c6e484",
   "metadata": {},
   "source": [
    "## Step 0: Converting raw data soruce into Parquet for optimized query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0727117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function needed:\n",
    "def extract_and_rename_columns(df):\n",
    "    \"\"\"\n",
    "    Extract shortened column names from parentheses in full column names.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with column names in format: (SHORT_NAME) Full Name Description\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (modified_df, column_mapping)\n",
    "        - modified_df: DataFrame with columns renamed to shortened names\n",
    "        - column_mapping: Dict mapping short names to full descriptions\n",
    "    \"\"\"\n",
    "    column_mapping = {}\n",
    "    rename_dict = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col.startswith('(') and ')' in col:\n",
    "            short_name = col.split(')')[0][1:]  # Extract text inside parentheses\n",
    "            full_name = col.split(')')[1].strip()  # Extract text after parentheses\n",
    "            column_mapping[short_name] = full_name\n",
    "            rename_dict[col] = short_name\n",
    "    \n",
    "    # Print the mapping for reference\n",
    "    print(\"Column mapping (shortened name -> full name):\")\n",
    "    for short, full in column_mapping.items():\n",
    "        print(f\"  {short:15} -> {full}\")\n",
    "    \n",
    "    # Rename columns in the dataframe\n",
    "    df_renamed = df.rename(columns=rename_dict)\n",
    "    \n",
    "    return df_renamed, column_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a32507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c5115e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = 'WhartonDataSource.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "# df[\"CUSIP\"] = df[\"CUSIP\"].apply(\n",
    "#     lambda x: str(x).strip() if pd.notna(x) else None\n",
    "# )\n",
    "# df[\"CUSIP\"].map(type).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37a720dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(tic) Ticker Symbol', '(datadate) Data Date - Dividends', '(conm) Company Name', '(cusip) CUSIP', '(cik) CIK Number', '(exchg) Stock Exchange Code', '(secstat) Security Status Marker', '(fic) Current ISO Country Code - Incorporation', '(tpci) Issue Type Code', '(add1) Address Line 1', '(add2) Address Line 2', '(add3) Address Line 3', '(add4) Address Line 4', '(addzip) Postal Code', '(busdesc) S&P Business Description', '(city) City', '(conml) Company Legal Name', '(costat) Active/Inactive Status Marker', '(county) County Code', '(dldte) Research Company Deletion Date', '(dlrsn) Research Co Reason for Deletion', '(ein) Employer Identification Number', '(fax) Fax Number', '(fyrc) Current Fiscal Year End Month', '(ggroup) GIC Groups', '(gind) GIC Industries', '(gsector) GIC Sectors', '(gsubind) GIC Sub-Industries', '(idbflag) International, Domestic, Both Indicator', '(incorp) Current State/Province of Incorporation Code', '(ipodate) Company Initial Public Offering Date', '(loc) Current ISO Country Code - Headquarters', '(naics) North American Industry Classification Code', '(phone) Phone Number', '(prican) Current Primary Issue Tag - Canada', '(prirow) Primary Issue Tag - Rest of World', '(priusa) Current Primary Issue Tag - US', '(sic) Standard Industry Classification Code', '(spcindcd) S&P Industry Sector Code', '(spcseccd) S&P Economic Sector Code', '(spcsrc) S&P Quality Ranking - Current', '(state) State/Province', '(stko) Stock Ownership Code', '(weburl) Web URL', '(adrrc) ADR Ratio - Daily', '(ajexdi) Adjustment Factor (Issue)-Cumulative by Ex-Date', '(anncdate) Dividend Declaration Date', '(capgn) Capital Gains - Daily', '(capgnpaydate) Capital Gains Payment Date', '(cheqv) Cash Equivalent Distributions', '(cheqvpaydate) Cash Equivalent Distributions per Share Payment ', '(cshoc) Shares Outstanding', '(cshtrd) Trading Volume - Daily', '(curcdd) ISO Currency Code - Daily', '(curcddv) ISO Currency Code - Dividend', '(div) Dividends per Share - Ex Date - Daily (Issue)', '(divd) Cash Dividends - Daily', '(divdpaydate) Cash Dividends - Daily Payment Date', '(divdpaydateind) Cash Dividends - Daily Payment Date Indicator', '(divsp) Special Cash Dividends - Daily', '(divsppaydate) Special Cash Dividends - Daily Payment Date', '(dvi) Indicated Annual Dividend - Current', '(dvrated) Indicated Annual Dividend Rate - Daily', '(eps) Current EPS', '(epsmo) Current EPS Month', '(iid) Issue ID - Dividends', '(paydate) Dividend Payment Date', '(paydateind) Dividend Payment Date Indicator', '(prccd) Price - Close - Daily', '(prchd) Price - High - Daily', '(prcld) Price - Low - Daily', '(prcod) Price - Open - Daily', '(prcstd) Price Status Code - Daily', '(recorddate) Dividend Record Date', '(trfd) Daily Total Return Factor', '(gvkey) Global Company Key - Dividends']\n",
      "Column mapping (shortened name -> full name):\n",
      "  tic             -> Ticker Symbol\n",
      "  datadate        -> Data Date - Dividends\n",
      "  conm            -> Company Name\n",
      "  cusip           -> CUSIP\n",
      "  cik             -> CIK Number\n",
      "  exchg           -> Stock Exchange Code\n",
      "  secstat         -> Security Status Marker\n",
      "  fic             -> Current ISO Country Code - Incorporation\n",
      "  tpci            -> Issue Type Code\n",
      "  add1            -> Address Line 1\n",
      "  add2            -> Address Line 2\n",
      "  add3            -> Address Line 3\n",
      "  add4            -> Address Line 4\n",
      "  addzip          -> Postal Code\n",
      "  busdesc         -> S&P Business Description\n",
      "  city            -> City\n",
      "  conml           -> Company Legal Name\n",
      "  costat          -> Active/Inactive Status Marker\n",
      "  county          -> County Code\n",
      "  dldte           -> Research Company Deletion Date\n",
      "  dlrsn           -> Research Co Reason for Deletion\n",
      "  ein             -> Employer Identification Number\n",
      "  fax             -> Fax Number\n",
      "  fyrc            -> Current Fiscal Year End Month\n",
      "  ggroup          -> GIC Groups\n",
      "  gind            -> GIC Industries\n",
      "  gsector         -> GIC Sectors\n",
      "  gsubind         -> GIC Sub-Industries\n",
      "  idbflag         -> International, Domestic, Both Indicator\n",
      "  incorp          -> Current State/Province of Incorporation Code\n",
      "  ipodate         -> Company Initial Public Offering Date\n",
      "  loc             -> Current ISO Country Code - Headquarters\n",
      "  naics           -> North American Industry Classification Code\n",
      "  phone           -> Phone Number\n",
      "  prican          -> Current Primary Issue Tag - Canada\n",
      "  prirow          -> Primary Issue Tag - Rest of World\n",
      "  priusa          -> Current Primary Issue Tag - US\n",
      "  sic             -> Standard Industry Classification Code\n",
      "  spcindcd        -> S&P Industry Sector Code\n",
      "  spcseccd        -> S&P Economic Sector Code\n",
      "  spcsrc          -> S&P Quality Ranking - Current\n",
      "  state           -> State/Province\n",
      "  stko            -> Stock Ownership Code\n",
      "  weburl          -> Web URL\n",
      "  adrrc           -> ADR Ratio - Daily\n",
      "  ajexdi          -> Adjustment Factor (Issue\n",
      "  anncdate        -> Dividend Declaration Date\n",
      "  capgn           -> Capital Gains - Daily\n",
      "  capgnpaydate    -> Capital Gains Payment Date\n",
      "  cheqv           -> Cash Equivalent Distributions\n",
      "  cheqvpaydate    -> Cash Equivalent Distributions per Share Payment\n",
      "  cshoc           -> Shares Outstanding\n",
      "  cshtrd          -> Trading Volume - Daily\n",
      "  curcdd          -> ISO Currency Code - Daily\n",
      "  curcddv         -> ISO Currency Code - Dividend\n",
      "  div             -> Dividends per Share - Ex Date - Daily (Issue\n",
      "  divd            -> Cash Dividends - Daily\n",
      "  divdpaydate     -> Cash Dividends - Daily Payment Date\n",
      "  divdpaydateind  -> Cash Dividends - Daily Payment Date Indicator\n",
      "  divsp           -> Special Cash Dividends - Daily\n",
      "  divsppaydate    -> Special Cash Dividends - Daily Payment Date\n",
      "  dvi             -> Indicated Annual Dividend - Current\n",
      "  dvrated         -> Indicated Annual Dividend Rate - Daily\n",
      "  eps             -> Current EPS\n",
      "  epsmo           -> Current EPS Month\n",
      "  iid             -> Issue ID - Dividends\n",
      "  paydate         -> Dividend Payment Date\n",
      "  paydateind      -> Dividend Payment Date Indicator\n",
      "  prccd           -> Price - Close - Daily\n",
      "  prchd           -> Price - High - Daily\n",
      "  prcld           -> Price - Low - Daily\n",
      "  prcod           -> Price - Open - Daily\n",
      "  prcstd          -> Price Status Code - Daily\n",
      "  recorddate      -> Dividend Record Date\n",
      "  trfd            -> Daily Total Return Factor\n",
      "  gvkey           -> Global Company Key - Dividends\n",
      "\n",
      "Renamed 76 columns successfully!\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n",
    "\n",
    "# Call the function\n",
    "df, col_mapping = extract_and_rename_columns(df)\n",
    "print(f\"\\nRenamed {len(col_mapping)} columns successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b77cd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_cols = [\"cusip\", \"addzip\"]\n",
    "\n",
    "for col in problem_cols:\n",
    "    df[col] = df[col].apply(lambda x: str(x).strip() if pd.notna(x) else None)\n",
    "\n",
    "\n",
    "df.to_parquet(\"WhartonDataSource.parquet\", engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50af4eff",
   "metadata": {},
   "source": [
    "## Step 1: Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42747b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1048575, 76)\n",
      "\n",
      "Columns: ['tic', 'datadate', 'conm', 'cusip', 'cik', 'exchg', 'secstat', 'fic', 'tpci', 'add1', 'add2', 'add3', 'add4', 'addzip', 'busdesc', 'city', 'conml', 'costat', 'county', 'dldte', 'dlrsn', 'ein', 'fax', 'fyrc', 'ggroup', 'gind', 'gsector', 'gsubind', 'idbflag', 'incorp', 'ipodate', 'loc', 'naics', 'phone', 'prican', 'prirow', 'priusa', 'sic', 'spcindcd', 'spcseccd', 'spcsrc', 'state', 'stko', 'weburl', 'adrrc', 'ajexdi', 'anncdate', 'capgn', 'capgnpaydate', 'cheqv', 'cheqvpaydate', 'cshoc', 'cshtrd', 'curcdd', 'curcddv', 'div', 'divd', 'divdpaydate', 'divdpaydateind', 'divsp', 'divsppaydate', 'dvi', 'dvrated', 'eps', 'epsmo', 'iid', 'paydate', 'paydateind', 'prccd', 'prchd', 'prcld', 'prcod', 'prcstd', 'recorddate', 'trfd', 'gvkey']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>datadate</th>\n",
       "      <th>conm</th>\n",
       "      <th>cusip</th>\n",
       "      <th>cik</th>\n",
       "      <th>exchg</th>\n",
       "      <th>secstat</th>\n",
       "      <th>fic</th>\n",
       "      <th>tpci</th>\n",
       "      <th>add1</th>\n",
       "      <th>...</th>\n",
       "      <th>paydate</th>\n",
       "      <th>paydateind</th>\n",
       "      <th>prccd</th>\n",
       "      <th>prchd</th>\n",
       "      <th>prcld</th>\n",
       "      <th>prcod</th>\n",
       "      <th>prcstd</th>\n",
       "      <th>recorddate</th>\n",
       "      <th>trfd</th>\n",
       "      <th>gvkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-09</td>\n",
       "      <td>AMERICAN AIRLINES GROUP INC</td>\n",
       "      <td>02376R102</td>\n",
       "      <td>6201</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>1 Skyview Drive</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>24.60</td>\n",
       "      <td>25.44</td>\n",
       "      <td>23.4501</td>\n",
       "      <td>23.95</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-10</td>\n",
       "      <td>AMERICAN AIRLINES GROUP INC</td>\n",
       "      <td>02376R102</td>\n",
       "      <td>6201</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>1 Skyview Drive</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>24.88</td>\n",
       "      <td>25.17</td>\n",
       "      <td>24.4100</td>\n",
       "      <td>24.54</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-11</td>\n",
       "      <td>AMERICAN AIRLINES GROUP INC</td>\n",
       "      <td>02376R102</td>\n",
       "      <td>6201</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>1 Skyview Drive</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>25.99</td>\n",
       "      <td>27.20</td>\n",
       "      <td>25.3700</td>\n",
       "      <td>25.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-12</td>\n",
       "      <td>AMERICAN AIRLINES GROUP INC</td>\n",
       "      <td>02376R102</td>\n",
       "      <td>6201</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>1 Skyview Drive</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>25.45</td>\n",
       "      <td>26.71</td>\n",
       "      <td>25.4500</td>\n",
       "      <td>26.20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-13</td>\n",
       "      <td>AMERICAN AIRLINES GROUP INC</td>\n",
       "      <td>02376R102</td>\n",
       "      <td>6201</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>1 Skyview Drive</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>26.23</td>\n",
       "      <td>26.30</td>\n",
       "      <td>25.5201</td>\n",
       "      <td>25.61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tic   datadate                         conm      cusip   cik  exchg  \\\n",
       "0  AAL 2013-12-09  AMERICAN AIRLINES GROUP INC  02376R102  6201     14   \n",
       "1  AAL 2013-12-10  AMERICAN AIRLINES GROUP INC  02376R102  6201     14   \n",
       "2  AAL 2013-12-11  AMERICAN AIRLINES GROUP INC  02376R102  6201     14   \n",
       "3  AAL 2013-12-12  AMERICAN AIRLINES GROUP INC  02376R102  6201     14   \n",
       "4  AAL 2013-12-13  AMERICAN AIRLINES GROUP INC  02376R102  6201     14   \n",
       "\n",
       "  secstat  fic  tpci             add1  ...  paydate  paydateind  prccd  prchd  \\\n",
       "0       A  USA     0  1 Skyview Drive  ...      NaT        None  24.60  25.44   \n",
       "1       A  USA     0  1 Skyview Drive  ...      NaT        None  24.88  25.17   \n",
       "2       A  USA     0  1 Skyview Drive  ...      NaT        None  25.99  27.20   \n",
       "3       A  USA     0  1 Skyview Drive  ...      NaT        None  25.45  26.71   \n",
       "4       A  USA     0  1 Skyview Drive  ...      NaT        None  26.23  26.30   \n",
       "\n",
       "     prcld  prcod prcstd recorddate  trfd gvkey  \n",
       "0  23.4501  23.95    3.0        NaT   1.0  1045  \n",
       "1  24.4100  24.54    3.0        NaT   1.0  1045  \n",
       "2  25.3700  25.44    3.0        NaT   1.0  1045  \n",
       "3  25.4500  26.20    3.0        NaT   1.0  1045  \n",
       "4  25.5201  25.61    3.0        NaT   1.0  1045  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "\n",
    "# Load the Wharton data\n",
    "file_path = 'WhartonDataSource.parquet'\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab5951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_rename_columns(df):\n",
    "    \"\"\"\n",
    "    Extract shortened column names from parentheses in full column names.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with column names in format: (SHORT_NAME) Full Name Description\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (modified_df, column_mapping)\n",
    "        - modified_df: DataFrame with columns renamed to shortened names\n",
    "        - column_mapping: Dict mapping short names to full descriptions\n",
    "    \"\"\"\n",
    "    column_mapping = {}\n",
    "    rename_dict = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col.startswith('(') and ')' in col:\n",
    "            short_name = col.split(')')[0][1:]  # Extract text inside parentheses\n",
    "            full_name = col.split(')')[1].strip()  # Extract text after parentheses\n",
    "            column_mapping[short_name] = full_name\n",
    "            rename_dict[col] = short_name\n",
    "    \n",
    "    # Print the mapping for reference\n",
    "    print(\"Column mapping (shortened name -> full name):\")\n",
    "    for short, full in column_mapping.items():\n",
    "        print(f\"  {short:15} -> {full}\")\n",
    "    \n",
    "    # Rename columns in the dataframe\n",
    "    df_renamed = df.rename(columns=rename_dict)\n",
    "    \n",
    "    return df_renamed, column_mapping\n",
    "\n",
    "# Call the function\n",
    "df, col_mapping = extract_and_rename_columns(df)\n",
    "print(f\"\\nRenamed {len(col_mapping)} columns successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb543e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49e6a1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key column info:\n",
      "Available key columns: ['tic', 'datadate', 'prccd', 'ajexdi', 'cshtrd', 'trfd']\n",
      "\n",
      "Data types:\n",
      "tic                 object\n",
      "datadate    datetime64[ns]\n",
      "prccd              float64\n",
      "ajexdi             float64\n",
      "cshtrd             float64\n",
      "trfd               float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "tic             0\n",
      "datadate        0\n",
      "prccd          17\n",
      "ajexdi         17\n",
      "cshtrd         25\n",
      "trfd        26100\n",
      "dtype: int64\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>datadate</th>\n",
       "      <th>prccd</th>\n",
       "      <th>ajexdi</th>\n",
       "      <th>cshtrd</th>\n",
       "      <th>trfd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-09</td>\n",
       "      <td>24.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43167060.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-10</td>\n",
       "      <td>24.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18648140.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-11</td>\n",
       "      <td>25.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38584270.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-12</td>\n",
       "      <td>25.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19977100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-13</td>\n",
       "      <td>26.23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12189890.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-16</td>\n",
       "      <td>26.61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13181320.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-17</td>\n",
       "      <td>26.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11398040.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-18</td>\n",
       "      <td>26.23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9989747.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-19</td>\n",
       "      <td>26.12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6908812.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-20</td>\n",
       "      <td>26.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7527964.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tic   datadate  prccd  ajexdi      cshtrd  trfd\n",
       "0  AAL 2013-12-09  24.60     1.0  43167060.0   1.0\n",
       "1  AAL 2013-12-10  24.88     1.0  18648140.0   1.0\n",
       "2  AAL 2013-12-11  25.99     1.0  38584270.0   1.0\n",
       "3  AAL 2013-12-12  25.45     1.0  19977100.0   1.0\n",
       "4  AAL 2013-12-13  26.23     1.0  12189890.0   1.0\n",
       "5  AAL 2013-12-16  26.61     1.0  13181320.0   1.0\n",
       "6  AAL 2013-12-17  26.10     1.0  11398040.0   1.0\n",
       "7  AAL 2013-12-18  26.23     1.0   9989747.0   1.0\n",
       "8  AAL 2013-12-19  26.12     1.0   6908812.0   1.0\n",
       "9  AAL 2013-12-20  26.33     1.0   7527964.0   1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect key columns\n",
    "print(\"Key column info:\")\n",
    "key_cols = ['tic', 'datadate', 'prccd', 'ajexdi', 'cshtrd', 'trfd']\n",
    "available_cols = [col for col in key_cols if col in df.columns]\n",
    "\n",
    "print(f\"Available key columns: {available_cols}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df[available_cols].dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df[available_cols].isnull().sum())\n",
    "print(f\"\\nSample data:\")\n",
    "df[available_cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e52899fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: 2000-01-03 00:00:00 to 2025-12-10 00:00:00\n",
      "Number of unique tickers: 167\n",
      "\n",
      "Top 10 tickers by number of records:\n",
      "tic\n",
      "LNT     6526\n",
      "MO      6526\n",
      "PSA     6526\n",
      "HBAN    6526\n",
      "TXN     6526\n",
      "ADP     6526\n",
      "TXT     6526\n",
      "JCI     6526\n",
      "MS      6526\n",
      "RF      6526\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check date range and unique tickers\n",
    "df['(datadate) Data Date - Dividends'] = pd.to_datetime(df['datadate'])\n",
    "\n",
    "print(f\"Date range: {df['datadate'].min()} to {df['datadate'].max()}\")\n",
    "print(f\"Number of unique tickers: {df['tic'].nunique()}\")\n",
    "print(f\"\\nTop 10 tickers by number of records:\")\n",
    "print(df['tic'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d42b33",
   "metadata": {},
   "source": [
    "## Step 2: Create WhartonDataSource Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec8da11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WhartonDataSource class created successfully!\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class DataSource(ABC):\n",
    "    \"\"\"Interface for fetching historical market data.\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_historical_data(self, tickers: List[str], start_date: str, end_date: str) -> pd.DataFrame:\n",
    "        \"\"\"Fetch historical data for given tickers and date range.\"\"\"\n",
    "        pass\n",
    "\n",
    "class WhartonDataSource(DataSource):\n",
    "    \"\"\"\n",
    "    Implementation of DataSource using Wharton WRDS data from Excel file.\n",
    "    \n",
    "    Expected columns:\n",
    "    - tic: Ticker Symbol\n",
    "    - datadate: Data Date\n",
    "    - prccd: Price Close Daily\n",
    "    - ajexdi: Adjustment Factor (cumulative by ex-date)\n",
    "    - cshtrd: Trading Volume Daily\n",
    "    - trfd: Daily Total Return Factor (optional, alternative to prccd*ajexdi)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_path: str, use_trfd: bool = False):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path : str\n",
    "            Path to the Wharton Excel/CSV file\n",
    "        use_trfd : bool\n",
    "            If True, use trfd (total return factor) directly.\n",
    "            If False, calculate adjusted price as prccd * ajexdi\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "        self.use_trfd = use_trfd\n",
    "        self.data = None\n",
    "        self._load_data()\n",
    "    \n",
    "    def _load_data(self):\n",
    "        \"\"\"Load and prepare data from file.\"\"\"\n",
    "        if not os.path.exists(self.file_path):\n",
    "            raise FileNotFoundError(f\"Data file not found at {self.file_path}\")\n",
    "        \n",
    "        # Load file (supports .xlsx and .csv)\n",
    "        if self.file_path.endswith('.xlsx') or self.file_path.endswith('.xls'):\n",
    "            self.data = pd.read_excel(self.file_path)\n",
    "        elif self.file_path.endswith('.parquet'):\n",
    "            problem_cols = [\"cusip\", \"addzip\"]\n",
    "            # parquet does not supported column with mixed types\n",
    "            for col in problem_cols:\n",
    "                df[col] = df[col].apply(lambda x: str(x).strip() if pd.notna(x) else None)\n",
    "            self.data = pd.read_parquet(self.file_path)\n",
    "        else:\n",
    "            raise TypeError(f\"Data file format is not supported, please use (.csv, .xlsx, or .parquet)\")\n",
    "        \n",
    "        # Ensure required columns exist\n",
    "        required_cols = ['tic', 'datadate']\n",
    "        missing_cols = [col for col in required_cols if col not in self.data.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "        \n",
    "        # Convert date column\n",
    "        self.data['datadate'] = pd.to_datetime(self.data['datadate'])\n",
    "        \n",
    "        # Calculate adjusted close price\n",
    "        if self.use_trfd:\n",
    "            if 'trfd' not in self.data.columns:\n",
    "                raise ValueError(\"trfd column not found but use_trfd=True\")\n",
    "            self.data['Adj Close'] = self.data['trfd']\n",
    "        else:\n",
    "            if 'prccd' not in self.data.columns or 'ajexdi' not in self.data.columns:\n",
    "                raise ValueError(\"prccd and ajexdi columns required when use_trfd=False\")\n",
    "            self.data['Adj Close'] = self.data['prccd'] * self.data['ajexdi']\n",
    "        \n",
    "        # Add volume if available\n",
    "        if 'cshtrd' in self.data.columns:\n",
    "            self.data['Volume'] = self.data['cshtrd']\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} records for {self.data['tic'].nunique()} tickers\")\n",
    "        print(f\"Date range: {self.data['datadate'].min()} to {self.data['datadate'].max()}\")\n",
    "    \n",
    "    def get_historical_data(self, tickers: List[str], start_date: str, end_date: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fetch historical adjusted prices for given tickers and date range.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Index: dates, Columns: tickers, Values: adjusted close prices\n",
    "        \"\"\"\n",
    "        start_ts = pd.Timestamp(start_date)\n",
    "        end_ts = pd.Timestamp(end_date)\n",
    "        \n",
    "        # Filter by date range and tickers\n",
    "        mask = (\n",
    "            (self.data['datadate'] >= start_ts) & \n",
    "            (self.data['datadate'] <= end_ts) & \n",
    "            (self.data['tic'].isin(tickers))\n",
    "        )\n",
    "        filtered = self.data.loc[mask, ['tic', 'datadate', 'Adj Close']].copy()\n",
    "        \n",
    "        if filtered.empty:\n",
    "            print(f\"Warning: No data found for specified tickers and date range\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Pivot to get tickers as columns, dates as index\n",
    "        result = filtered.pivot(index='datadate', columns='tic', values='Adj Close')\n",
    "        result = result.sort_index()\n",
    "        \n",
    "        # Report missing tickers\n",
    "        missing_tickers = set(tickers) - set(result.columns)\n",
    "        if missing_tickers:\n",
    "            print(f\"Warning: No data found for {len(missing_tickers)} tickers: {missing_tickers}\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_historical_data_with_volume(self, tickers: List[str], start_date: str, end_date: str) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Fetch historical price and volume data, organized by ticker.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, pd.DataFrame]\n",
    "            For each ticker: DataFrame indexed by date with 'Adj Close' and 'Volume' columns\n",
    "        \"\"\"\n",
    "        start_ts = pd.Timestamp(start_date)\n",
    "        end_ts = pd.Timestamp(end_date)\n",
    "        \n",
    "        result = {}\n",
    "        \n",
    "        for ticker in tickers:\n",
    "            mask = (\n",
    "                (self.data['datadate'] >= start_ts) & \n",
    "                (self.data['datadate'] <= end_ts) & \n",
    "                (self.data['tic'] == ticker)\n",
    "            )\n",
    "            ticker_data = self.data.loc[mask, ['datadate', 'Adj Close', 'Volume']].copy()\n",
    "            \n",
    "            if ticker_data.empty:\n",
    "                print(f\"Warning: No data found for {ticker}\")\n",
    "                continue\n",
    "            \n",
    "            ticker_data = ticker_data.set_index('datadate').sort_index()\n",
    "            result[ticker] = ticker_data\n",
    "        \n",
    "        return result\n",
    "\n",
    "print(\"WhartonDataSource class created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae710f",
   "metadata": {},
   "source": [
    "## Step 3: Test Basic Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c984968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1048575 records for 167 tickers\n",
      "Date range: 2000-01-03 00:00:00 to 2025-12-10 00:00:00\n",
      "Warning: No data found for tickers: {'GOOGL', 'SPY'}\n",
      "\n",
      "Retrieved data shape: (252, 2)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tic</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datadate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-02</th>\n",
       "      <td>185.64</td>\n",
       "      <td>370.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-03</th>\n",
       "      <td>184.25</td>\n",
       "      <td>370.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-04</th>\n",
       "      <td>181.91</td>\n",
       "      <td>367.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-05</th>\n",
       "      <td>181.18</td>\n",
       "      <td>367.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-08</th>\n",
       "      <td>185.56</td>\n",
       "      <td>374.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "tic           AAPL    MSFT\n",
       "datadate                  \n",
       "2024-01-02  185.64  370.87\n",
       "2024-01-03  184.25  370.60\n",
       "2024-01-04  181.91  367.94\n",
       "2024-01-05  181.18  367.75\n",
       "2024-01-08  185.56  374.69"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the data source\n",
    "wharton_source = WhartonDataSource('WhartonDataSource.parquet', use_trfd=False)\n",
    "\n",
    "# Test with a few tickers\n",
    "test_tickers = ['AAPL', 'MSFT', 'GOOGL']\n",
    "start_date = '2024-01-01'\n",
    "end_date = '2024-12-31'\n",
    "\n",
    "price_data = wharton_source.get_historical_data(test_tickers, start_date, end_date)\n",
    "print(f\"\\nRetrieved data shape: {price_data.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "price_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e67ac57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data per ticker:\n",
      "tic\n",
      "AAPL    0\n",
      "MSFT    0\n",
      "dtype: int64\n",
      "\n",
      "Data completeness: tic\n",
      "AAPL    100.0\n",
      "MSFT    100.0\n",
      "dtype: float64%\n"
     ]
    }
   ],
   "source": [
    "# Check for missing data\n",
    "print(\"Missing data per ticker:\")\n",
    "print(price_data.isnull().sum())\n",
    "print(f\"\\nData completeness: {(1 - price_data.isnull().sum() / len(price_data)) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3ebd7a",
   "metadata": {},
   "source": [
    "## Step 4: Test with SPY Verification (If Holdings File Available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84bb3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9afc63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdings file found! Running SPY verification...\n",
      "Found 505 constituents\n",
      "Warning: No data found for tickers: {'ECL', 'CZR', 'CTSH', 'PAYC', 'MOS', 'MLM', 'ORLY', 'AMZN', 'AMT', 'GPN', 'CMI', 'NFLX', 'D', 'AZO', 'TYL', 'AKAM', 'EG', 'CRL', 'MOH', 'LW', 'WYNN', 'CF', 'AWK', 'FMC', 'BSX', 'ALL', 'VLTO', 'BX', 'ACN', 'QCOM', 'IEX', 'VRTX', 'GNRC', 'CHRW', 'SYY', 'WBD', 'BK', 'SMCI', 'KKR', 'COF', 'CPT', 'NUE', 'BR', 'DAY', 'FTNT', 'DOV', 'MAR', 'AEP', 'WM', 'CSCO', 'GWW', 'TPR', 'PSX', 'CRWD', 'DD', 'SNDK', 'F', 'ICE', 'TDG', 'COR', 'DHI', 'BLDR', 'ESS', 'ETR', 'MET', 'GDDY', 'CRM', 'EXR', 'FIS', 'CPB', 'AVB', 'RVTY', 'CMCSA', 'ZBRA', 'WDC', 'AVGO', 'LKQ', 'IQV', 'CARR', 'BG', 'NI', 'IRM', 'TRMB', 'JBHT', 'KMX', 'EMN', 'DELL', 'KVUE', 'ZBH', 'UBER', 'DUK', 'TSLA', 'OTIS', 'EBAY', 'CFG', 'HCA', 'MCHP', 'PTC', 'LIN', 'WTW', 'EOG', 'JNPR', 'AMAT', 'BA', 'BRO', 'AIZ', 'EW', 'AMCR', 'VLO', 'MTB', 'HLT', 'VTR', 'HSIC', 'WDAY', 'INTU', 'JBL', 'LII', 'AES', 'AJG', 'ERIE', 'ALGN', 'DRI', 'NEE', 'CBOE', 'MAS', 'FOX', 'NVDA', 'CME', 'TECH', 'JKHY', 'LDOS', 'DPZ', 'IDXX', 'GEHC', 'GLW', 'CE', 'MAA', 'META', 'AME', 'CINF', 'BF-B', 'ROST', 'CAG', 'TTWO', 'CEG', 'FSLR', 'HSY', 'ENPH', 'PWR', 'FOXA', 'KR', 'BAX', 'PODD', 'PARA', 'OKE', 'FCX', 'ULTA', 'MCO', 'MA', 'CSX', 'SYF', 'POOL', 'LEN', 'GILD', 'EA', 'SW', 'USD', 'TFC', 'GRMN', 'IR', 'ADSK', 'BRK-B', 'PCG', 'GE', 'MNST', 'J', 'GD', 'WFC', 'NCLH', 'EL', 'RSG', 'DLTR', 'TDY', 'NWSA', 'URI', 'AFL', 'LYV', 'WELL', 'GOOGL', 'ON', 'CDNS', 'SBAC', 'TFX', 'IVZ', 'FDS', 'ABNB', 'ROL', 'VRSK', 'AVY', 'V', 'FTV', 'NVR', 'PKG', 'CPRT', 'HPE', 'CNC', 'TMUS', 'EIX', 'HIG', 'FFIV', 'KIM', 'HES', 'BLK', 'INCY', 'NDAQ', 'CCI', 'AOS', 'GEV', 'RJF', 'NWS', 'TSCO', 'SOLV', 'PFG', 'HOLX', 'NTAP', 'GS', 'MHK', 'ELV', 'XYL', 'L', 'LH', 'MPWR', 'PRU', 'TEL', 'SBUX', 'DIS', 'RCL', 'DOW', 'DOC', 'MDLZ', 'ROP', 'MMM', 'NOW', 'SNPS', 'ALLE', 'DFS', 'FANG', 'CMG', 'KDP', 'VST', 'REGN', 'MTCH', 'EQR', 'PLD', 'RL', 'BKNG', 'GOOG', 'EXPE', 'KEYS', 'PHM', 'COST', 'PYPL', 'MKTX', 'INTC', 'ABBV', 'EPAM', 'DLR', 'ACGL', 'ARE', 'STX', 'FAST', 'DXCM', 'ADM', 'IFF', 'SPY', 'HUBB', 'CPAY', 'FICO', 'ES', 'TT', 'APH', 'TER', 'YUM', 'NDSN', 'HII', 'APO', 'PH', 'LULU', 'WAT', 'K', 'LVS', 'CTVA', 'RMD', 'PLTR', 'HWM', 'VRSN', 'UDR', 'ALB', 'AXON', 'GEN', 'TRGP', 'NOC', 'UAL', 'DVN', 'TRV', 'MSCI', 'COO', 'ANSS', 'APTV', 'BXP', 'CDW', 'FI', 'BIIB', 'VICI', 'PCAR', 'TROW', 'SPGI', 'MRNA', 'ISRG', 'CSGP', 'HUM', 'HAL', 'DECK', 'IT', 'CLX', 'O', 'ANET', 'CHTR', 'PANW', 'REG', 'MTD', 'PNR', 'AMP', 'FE', 'NTRS', 'EQIX', 'EXPD', 'DVA', 'TPL', 'INVH', 'STLD', 'PM', 'A', 'LYB', 'CBRE', 'SPG', 'BKR', 'ODFL', 'MPC', 'STE', 'CHD', 'PEG', 'ADI', 'CB', 'CTRA', 'BWA', 'WAB', 'NXPI', 'VMC', 'DGX', 'NRG'}\n",
      "SPY data not available in Wharton source\n"
     ]
    }
   ],
   "source": [
    "# Import necessary functions from data_source module\n",
    "import sys\n",
    "sys.path.append('/Users/bouse/developer/CDS/DataQuality25/millennium-data-quality-25-26/backtester')\n",
    "from data_source import YahooFinanceDataSource\n",
    "\n",
    "# Check if holdings file exists\n",
    "holdings_file = 'holdings-daily-us-en-spy.xlsx'\n",
    "if os.path.exists(holdings_file):\n",
    "    print(\"Holdings file found! Running SPY verification...\")\n",
    "    \n",
    "    # Use YahooFinanceDataSource methods for holdings and portfolio calculation\n",
    "    yahoo_source = YahooFinanceDataSource()\n",
    "    holdings_df = yahoo_source.read_spy_holdings(holdings_file)\n",
    "    \n",
    "    # Fix ticker format\n",
    "    holdings_df['Ticker'] = holdings_df['Ticker'].replace({\n",
    "        'BRK.B': 'BRK-B',\n",
    "        'BF.B': 'BF-B',\n",
    "        '-': 'USD'\n",
    "    })\n",
    "    \n",
    "    print(f\"Found {len(holdings_df)} constituents\")\n",
    "    \n",
    "    # Get data for SPY and constituents\n",
    "    tickers = ['SPY'] + holdings_df['Ticker'].tolist()\n",
    "    price_data = wharton_source.get_historical_data(tickers, start_date, end_date)\n",
    "    \n",
    "    if 'SPY' in price_data.columns:\n",
    "        spy_data = price_data['SPY'].copy()\n",
    "        weighted_portfolio = yahoo_source.calculate_weighted_portfolio(holdings_df, price_data)\n",
    "        \n",
    "        print(f\"\\nSPY data points: {len(spy_data)}\")\n",
    "        print(f\"Portfolio data points: {len(weighted_portfolio)}\")\n",
    "    else:\n",
    "        print(\"SPY data not available in Wharton source\")\n",
    "else:\n",
    "    print(f\"Holdings file not found: {holdings_file}\")\n",
    "    print(\"Skipping SPY verification test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1145f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8013b7c3",
   "metadata": {},
   "source": [
    "## Step 5: Compare Wharton vs Yahoo Finance (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77102fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare a single ticker from both sources\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_ticker = 'AAPL'\n",
    "compare_start = '2024-01-01'\n",
    "compare_end = '2024-03-31'\n",
    "\n",
    "# Get Wharton data\n",
    "wharton_prices = wharton_source.get_historical_data([test_ticker], compare_start, compare_end)\n",
    "\n",
    "# Get Yahoo data for comparison (if available)\n",
    "try:\n",
    "    import yfinance as yf\n",
    "    yahoo_data = yf.download(test_ticker, start=compare_start, end=compare_end, auto_adjust=False)\n",
    "    yahoo_prices = yahoo_data['Adj Close']\n",
    "    \n",
    "    # Plot comparison\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "    \n",
    "    # Price comparison\n",
    "    ax1.plot(wharton_prices.index, wharton_prices[test_ticker], label='Wharton', alpha=0.7)\n",
    "    ax1.plot(yahoo_prices.index, yahoo_prices, label='Yahoo Finance', alpha=0.7)\n",
    "    ax1.set_title(f'{test_ticker} Price Comparison')\n",
    "    ax1.set_ylabel('Adjusted Close Price')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Difference\n",
    "    aligned = pd.concat([wharton_prices[test_ticker], yahoo_prices], axis=1, join='inner')\n",
    "    aligned.columns = ['Wharton', 'Yahoo']\n",
    "    aligned['Diff'] = aligned['Wharton'] - aligned['Yahoo']\n",
    "    aligned['Diff_Pct'] = (aligned['Diff'] / aligned['Yahoo']) * 100\n",
    "    \n",
    "    ax2.plot(aligned.index, aligned['Diff_Pct'])\n",
    "    ax2.set_title('Percentage Difference (Wharton - Yahoo)')\n",
    "    ax2.set_ylabel('Difference %')\n",
    "    ax2.set_xlabel('Date')\n",
    "    ax2.grid(True)\n",
    "    ax2.axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nDifference Statistics:\")\n",
    "    print(f\"Mean difference: {aligned['Diff_Pct'].mean():.4f}%\")\n",
    "    print(f\"Max difference: {aligned['Diff_Pct'].max():.4f}%\")\n",
    "    print(f\"Correlation: {aligned['Wharton'].corr(aligned['Yahoo']):.6f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not compare with Yahoo Finance: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd85dc38",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Add `WhartonDataSource` to [data_source.py](data_source.py)\n",
    "2. Implement additional methods:\n",
    "   - `read_spy_holdings()` (reuse from YahooFinanceDataSource)\n",
    "   - `calculate_weighted_portfolio()` (reuse)\n",
    "   - `detect_price_anomalies()` (reuse)\n",
    "   - `verify_spy_vs_constituents()` (reuse)\n",
    "3. Run full backtester tests with Wharton data\n",
    "4. Compare results with Yahoo Finance data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
